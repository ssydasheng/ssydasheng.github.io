---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a Member of Technical Staff at xAI, working on large language model reasoning.

Prior to xAI, I worked at NVIDIA for LLM model alignment and Amazon Advertising team for recommendation systems. 

I obtained my PhD degree at Department of Computer Science, University of Toronto, supervised by Roger Grosse. Previously, I did my undergraduate at Department of Electronic Engineering, Tsinghua University.

I am generally interested in all approaches to building strong AI models that acts intelligently, solves problems, and aids human. I am a believer of Andrew Ng's vision that "AI is the new electricity". I conduct research to realize this goal and enable AI for widerange positive impacts.

<!-- Specifically, my research at NVIDIA focuses on improving large language model performances in the post-training stage. My research involves model alignment algorithms, synthetic data generation, and long-horizon reason processes. -->

<!-- 
### NEWS

* 2024.12, my research regarding "**Knowledge Distillation in Model Alignment**" goes out in [NeMo-Aligner](https://docs.nvidia.com/nemo-framework/user-guide/latest/modelalignment/knowledge-distillation.html) and [NVIDIA Technical Blog](https://developer.nvidia.com/blog/data-efficient-knowledge-distillation-for-supervised-fine-tuning-with-nvidia-nemo-aligner/).
* 2024.06, our model alignment toolcase, **NeMo-Aligner**, is accepted in COLM 2024.
* 2024.04, our model **Nemotron-4-340B-Instruct** (me as the leading author) is realeased ([blog](https://developer.nvidia.com/blog/leverage-our-latest-open-models-for-synthetic-data-generation-with-nvidia-nemotron-4-340b/), [HF](https://huggingface.co/nvidia/Nemotron-4-340B-Instruct)). We also open-sourced our synthetic data generation pipeline to traing the model. -->